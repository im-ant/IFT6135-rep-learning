{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"vae.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"eece96f4a98e498daa799ed84a6031dc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d5846965f25f40d7bc600bfed013fa54","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5bdc5fe8f3e0456f8e8aa42343ac5ec0","IPY_MODEL_4aa769cc0b504260abbd1ebd28285512"]}},"d5846965f25f40d7bc600bfed013fa54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5bdc5fe8f3e0456f8e8aa42343ac5ec0":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_cffdd5d2222042be9b1300ccdce5982a","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9b4773909f6f49fc87a77140bfc519a9"}},"4aa769cc0b504260abbd1ebd28285512":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6bd2253a51d143b9809110697a949b11","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 78405632/? [00:02&lt;00:00, 31371760.88it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_387f396b11404fb691d83f0d1e650b54"}},"cffdd5d2222042be9b1300ccdce5982a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9b4773909f6f49fc87a77140bfc519a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6bd2253a51d143b9809110697a949b11":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"387f396b11404fb691d83f0d1e650b54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"091ee0292b664f34960219dae216b65b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ff55141203f44494ad6fc472aa0d25d9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a4034ef2b6e548759ced6d82ffb0a15b","IPY_MODEL_a1aa14dd5aea43588697d5c69e36b5a6"]}},"ff55141203f44494ad6fc472aa0d25d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a4034ef2b6e548759ced6d82ffb0a15b":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_555433d250264b2fac8b4543d9d49bba","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_388ee20db45b41a9ad14b7cb9ff3101a"}},"a1aa14dd5aea43588697d5c69e36b5a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_db2c8c101a42481eb4d085467646538f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 15687680/? [00:00&lt;00:00, 19796805.25it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_20e8182125104a1c9dbaa99a2c46df3a"}},"555433d250264b2fac8b4543d9d49bba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"388ee20db45b41a9ad14b7cb9ff3101a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"db2c8c101a42481eb4d085467646538f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"20e8182125104a1c9dbaa99a2c46df3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"96103bf81c00484995e90066999787ae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_75cd4573fd904b48b32428298943a39a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_97700f0f53a04b7a88810a2976146db6","IPY_MODEL_4bfb42c7dd5a4c3484ee68cae9c0a4ca"]}},"75cd4573fd904b48b32428298943a39a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"97700f0f53a04b7a88810a2976146db6":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c91a246fb4e74166ac2c25dfe4c2ef76","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7ee8fb830b164430b5ff9af0f142a94e"}},"4bfb42c7dd5a4c3484ee68cae9c0a4ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_58b5e9559e944890bcc38f1a4c13dba5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 15687680/? [00:00&lt;00:00, 26080247.24it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_87dd66c245414a42b3392dbf51798e70"}},"c91a246fb4e74166ac2c25dfe4c2ef76":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7ee8fb830b164430b5ff9af0f142a94e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"58b5e9559e944890bcc38f1a4c13dba5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"87dd66c245414a42b3392dbf51798e70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"xKzpzQWHrvwj","colab_type":"text"},"source":["# Question 1: VAE"]},{"cell_type":"markdown","metadata":{"id":"qC71Qv1-TtI-","colab_type":"text"},"source":["\n","Solution template for the question 1.6-1.7. This template consists of following steps. Except the step 2, you don't need to modify it to answer the questions.\n","1.   Initialize libraries\n","2.   **Insert the answers for the questions 1.1~1.5 below (this is the part you need to fill)**\n","3.   Define data loaders\n","4.   Define VAE network architecture\n","5.   Initialize the model and optimizer\n","6.   Train the model\n","7.   Save the model\n","8.   Load the model\n","9.   Evaluate the model with importance sampling"]},{"cell_type":"markdown","metadata":{"id":"mcs7QFvETxQJ","colab_type":"text"},"source":["Initialize libraries"]},{"cell_type":"code","metadata":{"id":"uLoP5GRpEPbI","colab_type":"code","colab":{}},"source":["import math\n","from torchvision.datasets import utils\n","import torch.utils.data as data_utils\n","import torch\n","import os\n","import numpy as np\n","from torch import nn\n","from torch.nn.modules import upsampling\n","from torch.functional import F\n","from torch.optim import Adam"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NTB40neeR6-k","colab_type":"text"},"source":["#### Insert **the answers for the questions 1.1~1.5 below**"]},{"cell_type":"code","metadata":{"id":"0Kr08AArNlHU","colab_type":"code","colab":{}},"source":["\n","def log_likelihood_bernoulli(mu, target):\n","    \"\"\" \n","    COMPLETE ME. DONT MODIFY THE PARAMETERS OF THE FUNCTION. Otherwise, tests might fail.\n","\n","    *** note. ***\n","\n","    :param mu: (FloatTensor) - shape: (batch_size x input_size) - The mean of Bernoulli random variables p(x=1).\n","    :param target: (FloatTensor) - shape: (batch_size x input_size) - Target samples (binary values).\n","    :return: (FloatTensor) - shape: (batch_size,) - log-likelihood of target samples on the Bernoulli random variables.\n","    \"\"\"\n","    # init\n","    batch_size = mu.size(0)\n","    mu = mu.view(batch_size, -1)\n","    target = target.view(batch_size, -1)\n","\n","    # ==\n","    # Bernoulli log likelihood\n","    ele_log_prob = ((target * mu.log())\n","                    + ((1-target) * (1-mu).log()))  # (batch, input)\n","    sample_log_prob = torch.sum(ele_log_prob, dim=1)  # (batch, )\n","\n","    # log_likelihood_bernoulli\n","    return sample_log_prob\n","\n","\n","def log_likelihood_normal(mu, logvar, z):\n","    \"\"\" \n","    COMPLETE ME. DONT MODIFY THE PARAMETERS OF THE FUNCTION. Otherwise, tests might fail.\n","\n","    *** note. ***\n","\n","    :param mu: (FloatTensor) - shape: (batch_size x input_size) - The mean of Normal distributions.\n","    :param logvar: (FloatTensor) - shape: (batch_size x input_size) - The log variance of Normal distributions.\n","    :param z: (FloatTensor) - shape: (batch_size x input_size) - Target samples.\n","    :return: (FloatTensor) - shape: (batch_size,) - log probability of the sames on the given Normal distributions.\n","    \"\"\"\n","    # init\n","    batch_size = mu.size(0)\n","    mu = mu.view(batch_size, -1)\n","    logvar = logvar.view(batch_size, -1)\n","    z = z.view(batch_size, -1)\n","\n","    # ==\n","    # Gaussian log likelihood\n","    ele_rel = logvar + ((z-mu).pow(2) / logvar.exp())  # (batch, input)\n","    ele_inv_ll = np.log(2*np.pi) + ele_rel  # add the log2pi constant\n","    batch_ll = (-1.0/2.0) * torch.sum(ele_inv_ll, dim=1)  # (batch, )\n","\n","    # NOTE maybe TODO: recheck my derivation of the log likelihood is correct\n","    # passed unit test but just to be sure\n","\n","    # log normal\n","    return batch_ll\n","\n","\n","def log_mean_exp(y):\n","    \"\"\" \n","    COMPLETE ME. DONT MODIFY THE PARAMETERS OF THE FUNCTION. Otherwise, tests might fail.\n","\n","    *** note. ***\n","\n","    :param y: (FloatTensor) - shape: (batch_size x sample_size) - Values to be evaluated for log_mean_exp. For example log proababilies\n","    :return: (FloatTensor) - shape: (batch_size,) - Output for log_mean_exp.\n","    \"\"\"\n","    # init\n","    batch_size = y.size(0)\n","    sample_size = y.size(1)\n","\n","    # ==\n","    # log mean exp\n","    ymax = y.max(dim=1, keepdim=True)[0]  # (batch, 1)\n","    exp_y = (y-ymax).exp()  # (batch, sample)\n","    sum_exp = torch.sum(exp_y, dim=1)  # (batch, )\n","    lme = ((1.0/sample_size) * sum_exp).log() + ymax.view(-1)\n","\n","    # NOTE maybe TODO: check mean is outside of sum (passed test but be sure)\n","\n","    # log_mean_exp\n","    return lme\n","\n","\n","def kl_gaussian_gaussian_analytic(mu_q, logvar_q, mu_p, logvar_p):\n","    \"\"\" \n","    COMPLETE ME. DONT MODIFY THE PARAMETERS OF THE FUNCTION. Otherwise, tests might fail.\n","\n","    *** note. ***\n","\n","    :param mu_q: (FloatTensor) - shape: (batch_size x input_size) - The mean of first distributions (Normal distributions).\n","    :param logvar_q: (FloatTensor) - shape: (batch_size x input_size) - The log variance of first distributions (Normal distributions).\n","    :param mu_p: (FloatTensor) - shape: (batch_size x input_size) - The mean of second distributions (Normal distributions).\n","    :param logvar_p: (FloatTensor) - shape: (batch_size x input_size) - The log variance of second distributions (Normal distributions).\n","    :return: (FloatTensor) - shape: (batch_size,) - kl-divergence of KL(q||p).\n","    \"\"\"\n","    # init\n","    batch_size = mu_q.size(0)\n","    mu_q = mu_q.view(batch_size, -1)\n","    logvar_q = logvar_q.view(batch_size, -1)\n","    mu_p = mu_p.view(batch_size, -1)\n","    logvar_p = logvar_p.view(batch_size, -1)\n","\n","    # ==\n","    # Gaussian analytical KLdiv\n","    ele_kl = (logvar_p - logvar_q - 1.0\n","              + (logvar_q.exp() / logvar_p.exp())\n","              + ((mu_q - mu_p).pow(2) / logvar_p.exp()))  # (batch, input)\n","    kld = (1.0/2.0) * torch.sum(ele_kl, dim=1)  # (batch, )\n","\n","    # kld\n","    return kld\n","\n","\n","def kl_gaussian_gaussian_mc(mu_q, logvar_q, mu_p, logvar_p, num_samples=1):\n","    \"\"\" \n","    COMPLETE ME. DONT MODIFY THE PARAMETERS OF THE FUNCTION. Otherwise, tests might fail.\n","\n","    *** note. ***\n","\n","    :param mu_q: (FloatTensor) - shape: (batch_size x input_size) - The mean of first distributions (Normal distributions).\n","    :param logvar_q: (FloatTensor) - shape: (batch_size x input_size) - The log variance of first distributions (Normal distributions).\n","    :param mu_p: (FloatTensor) - shape: (batch_size x input_size) - The mean of second distributions (Normal distributions).\n","    :param logvar_p: (FloatTensor) - shape: (batch_size x input_size) - The log variance of second distributions (Normal distributions).\n","    :param num_samples: (int) - shape: () - The number of sample for Monte Carlo estimate for KL-divergence\n","    :return: (FloatTensor) - shape: (batch_size,) - kl-divergence of KL(q||p).\n","    \"\"\"\n","    # init\n","    batch_size = mu_q.size(0)\n","    input_size = np.prod(mu_q.size()[1:])\n","    mu_q = mu_q.view(batch_size, -1).unsqueeze(1).expand(batch_size, num_samples, input_size)\n","    logvar_q = logvar_q.view(batch_size, -1).unsqueeze(1).expand(batch_size, num_samples, input_size)\n","    mu_p = mu_p.view(batch_size, -1).unsqueeze(1).expand(batch_size, num_samples, input_size)\n","    logvar_p = logvar_p.view(batch_size, -1).unsqueeze(1).expand(batch_size, num_samples, input_size)\n","\n","    # ==\n","    # Monte carlo kld\n","\n","    # Take sample from Q\n","    stdev_q = (((1.0/2.0) * logvar_q).exp())\n","    normal = torch.distributions.Normal(mu_q.float(), stdev_q.float())\n","    z = normal.sample()\n","\n","    # Compute the relative density under Q and P\n","    q_den = logvar_q + ((z-mu_q).pow(2) / logvar_q.exp())\n","    p_den = logvar_p + ((z-mu_p).pow(2) / logvar_p.exp())\n","    rel_den = q_den - p_den\n","\n","    # Compute KL\n","    batch_sample_sum = torch.sum(rel_den, dim=2)  # (batch, num_samples)\n","    batch_sum = torch.sum(batch_sample_sum, dim=1)  # (batch, )\n","    kld = (-1.0/2.0) * (1.0/num_samples) * batch_sum\n","\n","    # TODO NOTE maybe fix: there may be catastrophic cancellation happening\n","    # sometimes get negative values\n","\n","    # kld\n","    return kld"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r3v_ld3ITRFl","colab_type":"text"},"source":["#### Define data loaders"]},{"cell_type":"code","metadata":{"id":"oiK4L0TdETNb","colab_type":"code","colab":{}},"source":["def get_data_loader(dataset_location, batch_size):\n","    URL = \"http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/\"\n","    # start processing\n","    def lines_to_np_array(lines):\n","        return np.array([[int(i) for i in line.split()] for line in lines])\n","    splitdata = []\n","    for splitname in [\"train\", \"valid\", \"test\"]:\n","        filename = \"binarized_mnist_%s.amat\" % splitname\n","        filepath = os.path.join(dataset_location, filename)\n","        utils.download_url(URL + filename, dataset_location)\n","        with open(filepath) as f:\n","            lines = f.readlines()\n","        x = lines_to_np_array(lines).astype('float32')\n","        x = x.reshape(x.shape[0], 1, 28, 28)\n","        # pytorch data loader\n","        dataset = data_utils.TensorDataset(torch.from_numpy(x))\n","        dataset_loader = data_utils.DataLoader(x, batch_size=batch_size, shuffle=splitname == \"train\")\n","        splitdata.append(dataset_loader)\n","    return splitdata"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TZsL1gLLEVJM","colab_type":"code","outputId":"381947c0-a967-4bc7-ecbc-4a2fee243dbd","executionInfo":{"status":"ok","timestamp":1587740924266,"user_tz":240,"elapsed":19448,"user":{"displayName":"Anthony Chen","photoUrl":"","userId":"10539783115326379660"}},"colab":{"base_uri":"https://localhost:8080/","height":215,"referenced_widgets":["eece96f4a98e498daa799ed84a6031dc","d5846965f25f40d7bc600bfed013fa54","5bdc5fe8f3e0456f8e8aa42343ac5ec0","4aa769cc0b504260abbd1ebd28285512","cffdd5d2222042be9b1300ccdce5982a","9b4773909f6f49fc87a77140bfc519a9","6bd2253a51d143b9809110697a949b11","387f396b11404fb691d83f0d1e650b54","091ee0292b664f34960219dae216b65b","ff55141203f44494ad6fc472aa0d25d9","a4034ef2b6e548759ced6d82ffb0a15b","a1aa14dd5aea43588697d5c69e36b5a6","555433d250264b2fac8b4543d9d49bba","388ee20db45b41a9ad14b7cb9ff3101a","db2c8c101a42481eb4d085467646538f","20e8182125104a1c9dbaa99a2c46df3a","96103bf81c00484995e90066999787ae","75cd4573fd904b48b32428298943a39a","97700f0f53a04b7a88810a2976146db6","4bfb42c7dd5a4c3484ee68cae9c0a4ca","c91a246fb4e74166ac2c25dfe4c2ef76","7ee8fb830b164430b5ff9af0f142a94e","58b5e9559e944890bcc38f1a4c13dba5","87dd66c245414a42b3392dbf51798e70"]}},"source":["train, valid, test = get_data_loader(\"binarized_mnist\", 64)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/binarized_mnist_train.amat to binarized_mnist/binarized_mnist_train.amat\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eece96f4a98e498daa799ed84a6031dc","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Downloading http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/binarized_mnist_valid.amat to binarized_mnist/binarized_mnist_valid.amat\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"091ee0292b664f34960219dae216b65b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Downloading http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/binarized_mnist_test.amat to binarized_mnist/binarized_mnist_test.amat\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"96103bf81c00484995e90066999787ae","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8PoFxey7TUFS","colab_type":"text"},"source":["#### Define VAE network architecture\n"]},{"cell_type":"code","metadata":{"id":"POBmU6UCEb4l","colab_type":"code","colab":{}},"source":["class Encoder(nn.Module):\n","    def __init__(self, latent_size):\n","        super(Encoder, self).__init__()\n","        self.mlp = nn.Sequential(\n","            nn.Linear(784, 300),\n","            nn.ELU(),\n","            nn.Linear(300, 300),\n","            nn.ELU(),\n","            nn.Linear(300, 2 * latent_size),\n","        )\n","\n","    def forward(self, x):\n","        batch_size = x.size(0)\n","        z_mean, z_logvar = self.mlp(x.view(batch_size, 784)).chunk(2, dim=-1)\n","        return z_mean, z_logvar\n","\n","class Decoder(nn.Module):\n","    def __init__(self, latent_size):\n","        super(Decoder, self).__init__()\n","        self.mlp = nn.Sequential(\n","            nn.Linear(latent_size, 300),\n","            nn.ELU(),\n","            nn.Linear(300, 300),\n","            nn.ELU(),\n","            nn.Linear(300, 784),\n","        )\n","        \n","    def forward(self, z):\n","        return self.mlp(z) - 5.\n","\n","class VAE(nn.Module):\n","    def __init__(self, latent_size):\n","        super(VAE, self).__init__()\n","        self.encode = Encoder(latent_size)\n","        self.decode = Decoder(latent_size)\n","\n","    def forward(self, x):\n","        z_mean, z_logvar = self.encode(x)\n","        z_sample = z_mean + torch.exp(z_logvar / 2.) * torch.randn_like(z_logvar)\n","        x_mean = self.decode(z_sample)\n","        return z_mean, z_logvar, x_mean\n","\n","    def loss(self, x, z_mean, z_logvar, x_mean):\n","        ZERO = torch.zeros(z_mean.size())\n","        #kl = kl_gaussian_gaussian_mc(z_mean, z_logvar, ZERO, ZERO, num_samples=1000).mean()\n","        kl = kl_gaussian_gaussian_analytic(z_mean, z_logvar, ZERO, ZERO).mean()\n","        recon_loss = -log_likelihood_bernoulli(\n","            torch.sigmoid(x_mean.view(x.size(0), -1)),\n","            x.view(x.size(0), -1),            \n","        ).mean()\n","        return recon_loss + kl"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Phg07ERvTYuh","colab_type":"text"},"source":["#### Initialize a model and optimizer"]},{"cell_type":"code","metadata":{"id":"xTxgDwZfEesO","colab_type":"code","outputId":"e8b3c65b-2937-4dad-84e2-b16569a07f3f","executionInfo":{"status":"ok","timestamp":1587740929190,"user_tz":240,"elapsed":438,"user":{"displayName":"Anthony Chen","photoUrl":"","userId":"10539783115326379660"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["vae = VAE(100)\n","params = vae.parameters()\n","optimizer = Adam(params, lr=3e-4)\n","\n","print(next(vae.parameters()).device)\n","print(vae)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["cpu\n","VAE(\n","  (encode): Encoder(\n","    (mlp): Sequential(\n","      (0): Linear(in_features=784, out_features=300, bias=True)\n","      (1): ELU(alpha=1.0)\n","      (2): Linear(in_features=300, out_features=300, bias=True)\n","      (3): ELU(alpha=1.0)\n","      (4): Linear(in_features=300, out_features=200, bias=True)\n","    )\n","  )\n","  (decode): Decoder(\n","    (mlp): Sequential(\n","      (0): Linear(in_features=100, out_features=300, bias=True)\n","      (1): ELU(alpha=1.0)\n","      (2): Linear(in_features=300, out_features=300, bias=True)\n","      (3): ELU(alpha=1.0)\n","      (4): Linear(in_features=300, out_features=784, bias=True)\n","    )\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Oqw9SI7aTdtG","colab_type":"text"},"source":["### Train the model"]},{"cell_type":"code","metadata":{"id":"SWtQakAOEhxN","colab_type":"code","outputId":"92bf6baa-52c3-49f0-8472-ba498965c4d7","executionInfo":{"status":"ok","timestamp":1587741179976,"user_tz":240,"elapsed":249665,"user":{"displayName":"Anthony Chen","photoUrl":"","userId":"10539783115326379660"}},"colab":{"base_uri":"https://localhost:8080/","height":357}},"source":["for i in range(20):\n","    # train\n","    for x in train:\n","        optimizer.zero_grad() \n","        z_mean, z_logvar, x_mean = vae(x)\n","        loss = vae.loss(x, z_mean, z_logvar, x_mean)\n","        loss.backward()\n","        optimizer.step()\n","\n","    # evaluate ELBO on the valid dataset\n","    with torch.no_grad():\n","        total_loss = 0.\n","        total_count = 0\n","        for x in valid:\n","            total_loss += vae.loss(x, *vae(x)) * x.size(0)\n","            total_count += x.size(0)\n","        print('-elbo: ', (total_loss / total_count).item())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["-elbo:  165.1171112060547\n","-elbo:  144.0654296875\n","-elbo:  129.42237854003906\n","-elbo:  121.45259094238281\n","-elbo:  116.81476593017578\n","-elbo:  113.66443634033203\n","-elbo:  111.79532623291016\n","-elbo:  109.53128814697266\n","-elbo:  108.09529113769531\n","-elbo:  107.0516357421875\n","-elbo:  105.66487121582031\n","-elbo:  104.80563354492188\n","-elbo:  104.07299041748047\n","-elbo:  103.54907989501953\n","-elbo:  102.96051788330078\n","-elbo:  102.2616195678711\n","-elbo:  102.00286102294922\n","-elbo:  101.61691284179688\n","-elbo:  101.35663604736328\n","-elbo:  100.93311309814453\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HXp5vuhDTg1J","colab_type":"text"},"source":["Save the model"]},{"cell_type":"code","metadata":{"id":"JYfmW5TAElEO","colab_type":"code","outputId":"52a64b73-f030-47eb-c013-0f736b1e561d","executionInfo":{"status":"ok","timestamp":1587741184239,"user_tz":240,"elapsed":320,"user":{"displayName":"Anthony Chen","photoUrl":"","userId":"10539783115326379660"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["torch.save(vae, 'model.pt')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type VAE. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type Encoder. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type Decoder. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"8Iz6QX_KTizK","colab_type":"text"},"source":["Load the model"]},{"cell_type":"code","metadata":{"id":"Hqcb8BrmEnMh","colab_type":"code","colab":{}},"source":["vae = torch.load('model.pt')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OTpoVRncTmSR","colab_type":"text"},"source":["Evaluate the $\\log p_\\theta(x)$ of the model on test by using importance sampling"]},{"cell_type":"code","metadata":{"id":"tc2q6dxgEsIh","colab_type":"code","outputId":"39500bdc-fe3b-4b09-a185-8bf4480af214","executionInfo":{"status":"ok","timestamp":1587741306706,"user_tz":240,"elapsed":57535,"user":{"displayName":"Anthony Chen","photoUrl":"","userId":"10539783115326379660"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["total_loss = 0.\n","total_count = 0\n","with torch.no_grad():\n","    #x = next(iter(test))\n","    for x in test:\n","        # init\n","        K = 200\n","        M = x.size(0)\n","\n","        # Sample from the posterior\n","        z_mean, z_logvar = vae.encode(x)\n","        eps = torch.randn(z_mean.size(0), K, z_mean.size(1))\n","        z_samples = z_mean[:, None, :] + torch.exp(z_logvar / 2.)[:, None, :] * eps # Broadcast the noise over the mean and variance\n","\n","        # Decode samples\n","        z_samples_flat = z_samples.view(-1, z_samples.size(-1)) # Flatten out the z samples\n","        x_mean_flat = vae.decode(z_samples_flat) # Push it through\n","\n","        # Reshape images and posterior to evaluate probabilities\n","        x_flat = x[:, None].repeat(1, K, 1, 1, 1).reshape(M*K, -1)\n","        z_mean_flat = z_mean[:, None, :].expand_as(z_samples).reshape(M*K, -1)\n","        z_logvar_flat =  z_logvar[:, None, :].expand_as(z_samples).reshape(M*K, -1)\n","        ZEROS = torch.zeros(z_mean_flat.size())\n","\n","        # Calculate all the probabilities!\n","        log_p_x_z = log_likelihood_bernoulli(torch.sigmoid(x_mean_flat), x_flat).view(M, K)\n","        log_q_z_x = log_likelihood_normal(z_mean_flat, z_logvar_flat, z_samples_flat).view(M, K)\n","        log_p_z = log_likelihood_normal(ZEROS, ZEROS, z_samples_flat).view(M, K)\n","\n","        # Recombine them.\n","        w = log_p_x_z + log_p_z - log_q_z_x\n","        log_p = log_mean_exp(w)\n","\n","        # Accumulate\n","        total_loss += log_p.sum()\n","        total_count += M\n","      \n","print('log p(x):', (total_loss / total_count).item())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["log p(x): -95.33135223388672\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eQxV3xWJwM04","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}